j5ik2o {

  dynamo-db-journal {
    class = "com.github.j5ik2o.akka.persistence.dynamodb.journal.DynamoDBJournal"
    plugin-dispatcher = "akka.actor.default-dispatcher"

    # support for legacy config format.
    # true if reading old format configuration files, but normally should be false.
    legacy-config-format = false

    plug-in-lifecycle-handler-factory-class-name = ${j5ik2o.dynamo-db-defaults.plug-in-lifecycle-handler-factory-class-name}
    plug-in-lifecycle-handler-class-name = ${j5ik2o.dynamo-db-defaults.plug-in-lifecycle-handler-class-name}

    v1-async-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v1-async-client-factory-class-name}
    v1-sync-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v1-sync-client-factory-class-name}
    v1-dax-async-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v1-dax-async-client-factory-class-name}
    v1-dax-sync-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v1-dax-sync-client-factory-class-name}
    v2-async-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v2-async-client-factory-class-name}
    v2-sync-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v2-sync-client-factory-class-name}
    v2-dax-async-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v2-dax-async-client-factory-class-name}
    v2-dax-sync-client-factory-class-name = ${j5ik2o.dynamo-db-defaults.v2-dax-sync-client-factory-class-name}

    v1-journal-row-write-driver-factory-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.dao.v1.V1JournalRowWriteDriverFactory"
    v1-dax-journal-row-write-driver-factory-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.dao.v1.V1DaxJournalRowWriteDriverFactory"
    v2-journal-row-write-driver-factory-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.dao.v2.V2JournalRowWriteDriverFactory"
    v2-dax-journal-row-write-driver-factory-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.dao.v2.V2DaxJournalRowWriteDriverFactory"

    # column name defines
    columns-def {
      partition-key-column-name = "pkey"
      sort-key-column-name = "skey"
      persistence-id-column-name = "persistence-id"
      sequence-nr-column-name = "sequence-nr"
      deleted-column-name = "deleted"
      message-column-name = "message"
      ordering-column-name = "ordering"
      tags-column-name = "tags"
    }

    # the table name of journal
    table-name = "Journal"

    # the index name to read journal rows
    get-journal-rows-index-name = "GetJournalRowsIndex"

    # the separator for tags
    tag-separator = ","

    # consistent reads are possible, but at a higher cost.
    consistent-read = false

    # logical shard count
    shard-count = 64

    # specify the name of the provider class to generate the `PartitionKeyResolver`. Normally, you do not need to change this setting.
    partition-key-resolver-provider-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.PartitionKeyResolverProvider$Default"

    # `partition-key-resolver-class-name` specifies the implementation class that generates `pkey` from `PersistenceId` and `Sequence Number`.
    partition-key-resolver-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.PartitionKeyResolver$PersistenceIdBased"

    # specify the name of the provider class to generate the `SortKeyResolver`. Normally, you do not need to change this setting.
    sort-key-resolver-provider-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.SortKeyResolverProvider$Default"

    # `sort-key-resolver-class-name` specifies the implementation class that generates `skey` from `PersistenceId` and `Sequence Number`.
    sort-key-resolver-class-name = "com.github.j5ik2o.akka.persistence.dynamodb.journal.SortKeyResolver$PersistenceIdWithSeqNr"

    # Enable the queue to write journal.
    queue-enable = true

    # Queue buffer size
    queue-buffer-size = 512

    # Behavior when the queue overflows
    queue-overflow-strategy = "fail"

    # Number of queues
    # Multiple queues be created for the number of `queue-parallelism`.
    # The allocation to the queues is determined by `Math.abs(persistenceId.##) % queue-parallelism`.
    queue-parallelism = 1

    # Multiplicity of writings
    write-parallelism = 16

    # batch size of query
    query-batch-size = 512

    # batch size of replay
    replay-batch-size = 512

    # refresh interval when replay batch
    replay-batch-refresh-interval = null

    # soft delete, if false, hard delete.
    soft-delete = true

    write-backoff = ${j5ik2o.dynamo-db-defaults.write-backoff}

    read-backoff = ${j5ik2o.dynamo-db-defaults.read-backoff}

    dynamo-db-client = ${j5ik2o.dynamo-db-defaults.dynamo-db-client}

    journal-row-driver-wrapper-class-name = null

    metrics-reporter-provider-class-name = ${j5ik2o.dynamo-db-defaults.metrics-reporter-provider-class-name}

    metrics-reporter-class-name = ${j5ik2o.dynamo-db-defaults.metrics-reporter-class-name}

    trace-reporter-provider-class-name = ${j5ik2o.dynamo-db-defaults.trace-reporter-provider-class-name}

    trace-reporter-class-name = ${j5ik2o.dynamo-db-defaults.trace-reporter-class-name}
  }

}
